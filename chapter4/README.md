# 第四章 深层神经网络

在第三章介绍的神经网络中，都是线性模型，而深度学习的一大特点就是他是非线性的。
线性模型能够解决的问题是有限的，此时能够支持非线性模型就很重要。

## 激活函数去线性化

那么深度学习的去线性化解决方案就是在每一个节点是输出上，增加一个`非线性激活函数`以及`偏置项`进行过滤。有了这个非线性激活函数，那么整个神经网络就不再是线性模型了。
`book4.1.4-1.py`文件给出了加入了激活函数和偏置项的完整训练程序。

## 多层网络解决更深层次特征提取问题

异或问题是神经网络发展史上一个重要的问题。对于没有隐藏层的神经网络，是没有办法解决异或问题的。

但是一旦加上隐藏层后，通过隐藏层的可以抽取输入层更高维度的特征。这点很重要。详见P74

## 损失函数

神经网络模型的效果和优化的目标是通过`损失函数（loss function）`来定义的。
`交叉熵`刻画了两个概率分布之间的距离，他是分类问题中比较常用的一种损失函数。详见P75

### 自定义损失函数

通过`tf.where`函数完成选择操作，`tf.greater`函数来比较张量中每个元素的大小。
